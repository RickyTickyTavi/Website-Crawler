# Website Crawler

With a small group I was project lead for, we engineered a website scraper that analyzes static content of a website and provides statistical analysis on the findings. This software focuses on static content 
of hypertext markup language (HTML) pages. The static content that this software system will concern itself with is: images, javascript, cascading style sheets (CSS), hyperlinks, and data files. The data files category will contain archives to include zip, tar, and 7z files; video containers to include mkv and mp4; audio containers to include m4a, mka, and ogg; and finally, other data files including deb, exe, and cpp files.

The only parameters required at the interface will be the path to local copy of the site and one or more URLs to the local directory structure.

"www.example.com"

for example, will run the program

After you run the program on the directory in question, you should receive output in the form of a JSON file, an Excel file, and a text file.

